**Отчёт по обработке датасета habr.csv**

**Выбор модели - LogisticRegression**

**ЭТАП №1 - ПОДГОТОВКА ДАННЫХ И ФИЧ**

1. Преодбработка данных:
Все текстовые поля были преобразованы в нижний регистр (title, keywords, text) и очищены:
сжатие пробелов до одного, обрезка по краям, удаление URL адресов из текстов.
2. Обработали хабы - вернув их список
3. Формирование объединённого текста
Создана колонка full_text как конкатенация:
cleaned_title + " " + cleaned_keywords + " " + cleaned_text.
4. Удалили короткие записи длиной <50 символов, отобраны хабы которые встречаются больше 10 раз,
удалили записи, где количество хабов <3
5. Результат - сохраненный файл processed_habr.pkl

**ЭТАП №2 - ПЕРВАЯ ПОПЫТКА ОБУЧЕНИЯ МОДЕЛИ**

1. Применён MultiLabelBinarizer для преобразования списков хабов в бинарную матрицу 
2. Отобраны хабы, встречающиеся ≥ 2 раз
3. Перестроен MultiLabelBinarizer на отфильтрованных хабах
4. С помощью TfidfVectorizer векторизуем признак full_text
5. Используем MultiOutputClassifier, внутри которого используем базовый
классификатор LogisticRegression
6. Для оценки качества используем: Jaccard Score, Hamming Loss
7. Результат - получили достаточно низкий JaccardScore, но достаточно хороший Hamming Loss,
нашли места где можно улучшить модель - использовать больше признаков, вычленить ключевые слова из full_text,
увеличить количество признаков для TF-IDF векторизации

**ЭТАП №3 - ВЫЧЛЕНЕНИЕ КЛЮЧЕВЫХ СЛОВ ИЗ FULL TEXT**

1. Выбрали библиотеку YAKE - для извлечения ключевых слов
2. Цель - автоматически выделить ключевые фразы из текстов статей Хабра
3. Для проверки работоспособности данной библиотеку используем сэмпл на 20к записей
4. Параметры для YAKE - максимальная длина фразы 3 слова, берем 15 ключевых фраз на текст, 
фильтруем дубликаты, язык русский, также задали список из русских стоп-слов
5. Для каждого текста в cleaned_text вызван kw_extractor.extract_keywords()
6. Результат: колонка text_main со списком ключевых фраз, данные сохранены в data/sample_20k_yake_extracted.pkl 

**ЭТАП №4 - обучение модели классификации хабов на выборке 20000 записей**

1. Цель - Построить и оценить модель мультиклассовой классификации, предсказывающую тематические хабы статей
на основе 20000 записей, которые мы подготовили с помощью YAKE
2. Добавляем фичу username
3. Отобраны хабы, встречающиеся ≥ 2 раз (valid_hub_mask)
4. Удалены статьи без валидных хабов (non_empty)
5. Объединяются: cleaned_title + cleaned_keywords + text_main → колонка full_text_with_yake
6. Задаем более "хорошие/мощные" параметры TF-IDF:
   Параметры TfidfVectorizer:
      max_features=2000 — ограничение числа признаков
      ngram_range=(1, 4) — униграммы–4‑граммы
      min_df=3, max_df=0.75 — фильтрация редких/частых терминов
      стоп‑слова — 15 распространённых русских слов
      sublinear_tf=True, norm='l2' — сглаживание и нормализация
7.  Задаем MultiOutputClassifier — мультивыходный классификатор
   Базовый алгоритм: LogisticRegression с параметрами
     max_iter=1000 — максимальное число итераций
     class_weight='balanced' — учёт дисбаланса классов
     C=0.5 — регуляризация
     solver='liblinear' — оптимизатор для малых данных
     random_state=42 — воспроизводимость
8. Полученные показатели:
    Jaccard Score:0.3788
       Интерпретация: в среднем 37.9% пересечений между предсказанными и истинными хабами для каждой статьи. Это базовый, 
       но не выдающийся результат — модель улавливает часть закономерностей, но есть значительный потенциал для улучшения.
    Hamming Loss:0.0073
       Интерпретация: лишь 0.73% меток (хабов) предсказываются неверно. Низкий показатель говорит о хорошей общей точности 
       на уровне отдельных классов.
9. Главный вывод этого этапа заключается в том, что удалось получить значительный прирост качества
с помощью вычленения ключевых фраз, можем переходить к обучению на всех статьях


**ЭТАП №5 - вычленених ключевых фраз на всех статьях датасета**

1. Цель - Извлечь и структурировать ключевые смысловые фразы из текстов всех статей датасета с помощью алгоритма 
YAKE для последующего использования в задачах анализа и классификации
2. Файл: data/processed_habr.pkl, объём: 98064 текста
3. Пример статей, у которых вычленении ключевые фразы:
['apple newton messagepad', 'дополненной реальности google', 'продукт компании google', 'очки google glass',
'реальности google glassgoogle', 'смарт очки google', 'университета apple newton', 'glass продукт компании',
'производства dvd могла', 'атмосферу виртуальной реальности', 'виртуальной реальности инженер', 
'сфере виртуальной реальности', 'виртуальной реальности решила', 'шлеме виртуальной реальности', 
'очки дополненной реальности']
4. Результат - успешно извлечены ключевые фразы из всех статей датасета, результаты сохранены в двух форматах для гибкости использования.

**ЭТАП №6 - ПЕРЕХОДИМ К ОБУЧЕНИЮ НА ВСЕХ СТАТЬЯХ ДАТАСЕТА**

1. Построить и оценить модель мультиклассовой классификации, предсказывающую тематические хабы статей на основе выборки 
из записей, предварительно обработанных с помощью алгоритма YAKE
2. Затягиваем еще одну фичу, помимо username, берем time
3. Применён TfidfVectorizer с параметрами:
      max_features=40000 — ограничение числа признаков
      ngram_range=(1,3) — униграммы–триграммы
      min_df=2, max_df=0.8 — фильтрация редких/частых терминов
      список стоп‑слов (19 русских слов)
      sublinear_tf=True, norm='l2' — сглаживание и нормализация
4. Из даты публикации (time) извлечены: год, месяц, день недели, час.
Кодирование: OneHotEncoder (sparse, drop='first')
5. Используем классификатор: MultiOutputClassifier (мультивыходный).
   Базовый алгоритм: LogisticRegression с параметрами:
     max_iter=2000 — максимальное число итераций
     class_weight='balanced' — учёт дисбаланса классов
     C=0.5 — регуляризация
     solver='liblinear' — оптимизатор
     random_state=42 — воспроизводимость 
     tol=1e-4 — критерий остановки
6. Jaccard Score:0.3700
     Интерпретация: доля пересечений между предсказанными и истинными хабами для каждой статьи. 
     Значение 0.3700 указывает на умеренный уровень соответствия.
   Hamming Loss: 0.0060
     Интерпретация: доля неверно предсказанных меток.
     Низкий показатель (0.0060) свидетельствует о высокой точности на уровне отдельных классов.

**ЭТАП №7 - ФИНАЛЬНОЕ ОБУЧЕНИЕ**

1. Цель - использовав опыт предыдущих обучений получить максимальные метрики качества, обогатить нашу лучшую модель 
дополнительными метриками, например F1 Micro, F1 Macro, Precision Micro, Recall Micro, а также использовать кросс-валидацию
2. Если сравнивать с предыидущими моделями:
      увеличили регуляризацию, выставили l2 штраф, использовали кросс-валидацию:
      Средние показатели по фолдам:
        Jaccard Score (samples): 0.3835±0.0016;
        F1 Micro: 0.5183±0.0019;
        F1 Macro: 0.5366±0.0028;
        Hamming Loss: 0.0126±0.0001
3. Интерпретация:
     Jaccard ~0.38 указывает на умеренное пересечение предсказанных и истинных хабов.
     Низкий Hamming Loss (~0.0126) подтверждает высокую точность на уровне отдельных классов.
     F1‑меры >0.5 свидетельствуют о сбалансированности precision и recall.
4. Финальные метрики:
     Jaccard Score (samples): 0.3852 — 38.5% пересечений между предсказанными и истинными хабами.
     Hamming Loss: 0.0128 — 1.28% неверно предсказанных меток.
     F1 Micro: 0.5188 — сбалансированная точность/полнота по всем классам.
     F1 Macro: 0.5400 — учёт дисбаланса классов.
     Precision Micro: 0.4031 — доля верно предсказанных хабов среди всех предсказанных.
     Recall Micro: 0.7274 — доля верно предсказанных хабов среди всех истинных.

5. Достигнуто максимальное качество для текущей архитектуры (в моему случае):
     Jaccard Score: 0.3852 на тесте (против 0.3700 в предыдущих итерациях);
     Hamming Loss: 0.0128 (минимальное значение).

**ЭТАП №8 - ТЕСТИРОВАНИЕ**

Добавлены пару тестов для статей с хабра - пока не по url, вбивал фичи вручную:
На простых и однозначных статьях (с чёткой тематикой и явными ключевыми словами) модель демонстрирует хорошую точность: 
в большинстве случаев корректно предсказывает 2–3 из 3 возможных хабов. 
Например, для текста про нейросети и машинное обучение модель уверенно выделяет соответствующие хабы, почти не допуская ошибок. 
Это говорит о том, что базовая логика классификации работает корректно, когда признаки темы выражены явно.
Однако на текстах со смежной или неоднозначной тематикой качество предсказаний заметно снижается.
Модель часто путает близкие по смыслу хабы — например, может отнести статью о робототехнике к хабу «автоматизация», 
или смешать хабы «космос» и «технологии будущего».

**ЭТАП №9 - ВЫВОДЫ**

Трудности, с которыми стоклнулся при обучении и которые не дали показать более качественные метрики:
1. Высокая многоклассовость
2. Дисбаланс классов
3. Некоторые хабы очень похожи по смыслу
4. У линейных моделей нет понимания контекста, возможно далее DL модели дадут более хороший результат

Что можно улучшить?
1. Возможно, найти какие-нибудь дополнительные фичи
2. Использовать Bert вместо TF-IDF
3. Объединить синонимичные хабы(?)
4. Провести лемматизацию
5. Проанализировать статьи с Jaccrd=0 и изучить причины
