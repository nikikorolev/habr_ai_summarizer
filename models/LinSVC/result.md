# Отчёт по модели классификации хабов статей Habr


## ЭТАП 1: ПОДГОТОВКА ДАННЫХ

### 1.1 Исходные параметры
- **Объём выборки:** 20,000 статей (случайная выборка из полного датасета)
- **Целевая переменная:** тематические хабы 
- **Признаки:** текст статьи, заголовок, ключевые слова, мета-информация

### 1.2 Предобработка текста
**Объединение текстовых полей:**
- Конкатенация: `текст + заголовок + ключевые слова`
- Преобразование списков ключевых слов в строки

**Базовая очистка текста:**
- Приведение к нижнему регистру
- Удаление HTML-тегов
- Удаление URL-адресов и email
- Удаление специальных символов
- Сжатие пробелов

**Извлечение мета-признаков:**
- `text_length`: длина текста в символах
- `word_count`: количество слов
- `author_popularity`: популярность автора (по количеству статей)

### 1.3 Обработка целевых переменных
- **Проблема:** высокая разреженность, большая часть хабов встречаются <10 раз
- **Решение:** фильтрация редких хабов
  - Порог: `MIN_HUB_FREQ = 10`

---

## ЭТАП 2: ВЕКТОРИЗАЦИЯ И ФОРМИРОВАНИЕ ПРИЗНАКОВ

### 2.1 Текстовая векторизация
**Метод:** TF-IDF (Term Frequency-Inverse Document Frequency)

**Конфигурация:**
- `max_features=3000`: ограничение словаря частотными терминами
- `ngram_range=(1,2)`: учёт униграмм и биграмм
- `min_df=3`: игнорирование терминов, встречающихся <3 раз
- `max_df=0.85`: игнорирование слишком частых терминов
- `stop_words`: русские стоп-слова из NLTK (158 слов)
- `analyzer='word'`: токенизация по словам

### 2.2 Преобразование целевых переменных
- **Формат:** бинарная матрица 14,876 × 487
- **Метод:** `MultiLabelBinarizer`
- **Особенность:** каждая статья может иметь несколько хабов (мультилабельная классификация)

### 2.3 Разделение данных
- **Пропорция:** 80/20 (train/test)
- **Объём обучающей выборки:** 11,900 статей
- **Объём тестовой выборки:** 2,976 статей
- **Стратификация:** не применялась (ограничения мультилабельной классификации)

---

## ЭТАП 3: АРХИТЕКТУРА МОДЕЛИ

### 3.1 Выбор алгоритма
- **Подход:** One-vs-Rest (бинарная классификация для каждого хаба)
- **Базовый классификатор:** LinearSVC (линейный метод опорных векторов)

**Обоснование выбора:**
- Эффективность с разреженными данными
- Масштабируемость на тысячи классов
- Интерпретируемость весов признаков

### 3.2 Конфигурация модели
```python
OneVsRestClassifier(
    LinearSVC(
        C=0.7,               
        class_weight='balanced', 
        max_iter=10000,  
        random_state=42,    
        dual=False        
    ),
    n_jobs=-1               
)
```

---

## ЭТАП 4: РЕЗУЛЬТАТЫ ОЦЕНКИ


- Micro F1 = 0.4404
- Macro F1 = 0.2888

### 4.1 Детальный анализ результатов
- Micro-F1 = 0.4404:

Модель правильно предсказывает хабы в 44% случаев

Для 20,000 статей это означает ~8,800 правильных предсказаний

Положительный аспект: предсказания семантически осмысленны

- Macro-F1 = 0.2888:

Сильный дисбаланс качества между хабами

Популярные хабы предсказываются хорошо (F1 ~0.6-0.7)

Редкие хабы практически не предсказываются (F1 ~0.0-0.1)

